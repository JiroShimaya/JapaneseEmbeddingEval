{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import Tensor\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "def average_pool(last_hidden_states: Tensor,\n",
    "                 attention_mask: Tensor) -> Tensor:\n",
    "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('intfloat/multilingual-e5-large')\n",
    "model = AutoModel.from_pretrained('intfloat/multilingual-e5-large').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "batch_size = 8\n",
    "def encode(input_texts):\n",
    "    with torch.no_grad():\n",
    "        all_embeddings = []\n",
    "        for i in tqdm(range(0, len(input_texts), batch_size)):\n",
    "            batch_texts = input_texts[i:i+batch_size]\n",
    "            # Tokenize the input texts\n",
    "            batch_dict = tokenizer(batch_texts, max_length=512, padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "\n",
    "            outputs = model(**batch_dict)\n",
    "            embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
    "\n",
    "            # (Optionally) normalize embeddings\n",
    "            embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "            all_embeddings.append(embeddings.cpu())\n",
    "            \n",
    "    return torch.cat(all_embeddings, dim=0).numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_pair_id</th>\n",
       "      <th>yjcaptions_id</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>100312_421853-104611-31624</td>\n",
       "      <td>レンガの建物の前を、乳母車を押した女性が歩いています。</td>\n",
       "      <td>厩舎で馬と女性とが寄り添っています。</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentence_pair_id               yjcaptions_id                    sentence1  \\\n",
       "0                0  100312_421853-104611-31624  レンガの建物の前を、乳母車を押した女性が歩いています。   \n",
       "\n",
       "            sentence2  label  \n",
       "0  厩舎で馬と女性とが寄り添っています。    0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from urllib.request import urlopen\n",
    "jsts_url = \"https://raw.githubusercontent.com/yahoojapan/JGLUE/main/datasets/jsts-v1.1/valid-v1.1.json\"\n",
    "df = pd.DataFrame([json.loads(line) for line in urlopen(jsts_url).readlines()])\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1457, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fe298e8f7de4f8b9f55f950b4ba463f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d42914e4a164b5ea241a403cac3b5f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "((1457, 1024), (1457, 1024))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence1_embs = encode(df[\"sentence1\"].values.tolist())\n",
    "sentence2_embs = encode(df[\"sentence2\"].values.tolist())\n",
    "sentence1_embs.shape, sentence2_embs.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.809871019433716"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "\n",
    "df[\"similarity\"] = [1 - cosine(s1, s2) for s1, s2 in zip(sentence1_embs, sentence2_embs)]\n",
    "spearmanr(df[\"similarity\"], df[\"label\"])[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSICK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_ID</th>\n",
       "      <th>data</th>\n",
       "      <th>sentence_A_En</th>\n",
       "      <th>sentence_B_En</th>\n",
       "      <th>entailment_label_En</th>\n",
       "      <th>relatedness_score_En</th>\n",
       "      <th>corr_entailment_labelAB_En</th>\n",
       "      <th>corr_entailment_labelBA_En</th>\n",
       "      <th>sentence_A_Ja</th>\n",
       "      <th>sentence_B_Ja</th>\n",
       "      <th>entailment_label_Ja</th>\n",
       "      <th>relatedness_score_Ja</th>\n",
       "      <th>image_ID</th>\n",
       "      <th>original_caption</th>\n",
       "      <th>semtag_short</th>\n",
       "      <th>semtag_long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>test</td>\n",
       "      <td>There is no boy playing outdoors and there is ...</td>\n",
       "      <td>A group of kids is playing in a yard and an ol...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>戸外で遊んでいる男の子は一人もおらず、微笑んでいる男性は一人もいない</td>\n",
       "      <td>子供たちのグループが庭で遊んでいて、後ろの方には年を取った男性が立っている</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3155657768_b83a7831e5.jpg</td>\n",
       "      <td>The children are playing outdoors , while a ma...</td>\n",
       "      <td>Negation#Numerical</td>\n",
       "      <td>Numerical;人;名詞,接尾,助数詞,*#Negation;ない;助動詞,*,*,*#...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pair_ID  data                                      sentence_A_En  \\\n",
       "0        6  test  There is no boy playing outdoors and there is ...   \n",
       "\n",
       "                                       sentence_B_En entailment_label_En  \\\n",
       "0  A group of kids is playing in a yard and an ol...             neutral   \n",
       "\n",
       "   relatedness_score_En corr_entailment_labelAB_En corr_entailment_labelBA_En  \\\n",
       "0                   3.3                        NaN                        NaN   \n",
       "\n",
       "                        sentence_A_Ja                          sentence_B_Ja  \\\n",
       "0  戸外で遊んでいる男の子は一人もおらず、微笑んでいる男性は一人もいない  子供たちのグループが庭で遊んでいて、後ろの方には年を取った男性が立っている   \n",
       "\n",
       "  entailment_label_Ja  relatedness_score_Ja                   image_ID  \\\n",
       "0       contradiction                   2.3  3155657768_b83a7831e5.jpg   \n",
       "\n",
       "                                    original_caption        semtag_short  \\\n",
       "0  The children are playing outdoors , while a ma...  Negation#Numerical   \n",
       "\n",
       "                                         semtag_long  \n",
       "0  Numerical;人;名詞,接尾,助数詞,*#Negation;ない;助動詞,*,*,*#...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"https://github.com/verypluming/JSICK/raw/main/jsick/test.tsv\", sep=\"\\t\")\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4927, 16)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73a8a457b90c4acd9248bc9d13be0eab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/616 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb4d10d5b92d470497cad2e100f388fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/616 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "((4927, 1024), (4927, 1024))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence1_embs = encode(df[\"sentence_A_Ja\"].values.tolist())\n",
    "sentence2_embs = encode(df[\"sentence_B_Ja\"].values.tolist())\n",
    "sentence1_embs.shape, sentence2_embs.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7838394132798657"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "from scipy.stats import spearmanr\n",
    "df[\"similarity\"] = [1 - cosine(s1, s2) for s1, s2 in zip(sentence1_embs, sentence2_embs)]\n",
    "spearmanr(df[\"similarity\"], df[\"relatedness_score_Ja\"])[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "02c2702a58ea2fe60fd5f26dd152a70e7993d77024040a4f035d0ea16923b730"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
